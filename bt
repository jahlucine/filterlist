
\subsection{Normal Distribution}
$$X \sim \mathcal{N}\left(\mu, \sigma^{2}\right)$$
$$f_{X}(x)=\frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{(x-\mu)^{2}}{2 \sigma^{2}}\right)$$

\subsection{ $\sigma$-algebra}
Let $\Omega$ be a set. A collection $\mathcal{A}$ of subsets of $\Omega$ is a $\sigma$-algebra on $\Omega$, if and only if it satisfies all the following properties:
\begin{itemize}
\item $\Omega, \emptyset \in \mathcal{A}$
\item  For all $A \in \mathcal{A}, A^{c} \in \mathcal{A}$
\item  For all sequence $\left(A_{n}\right)_{n=1}^{\infty}$ of elements of $\mathcal{A}, \cup_{n=1}^{\infty} A_{n}
 \in \mathcal{A}$
\end{itemize}


\subsection{Brownian Motion} 
A Brownian motion is a stochastic process $\left\{B_{t}\right\}_{t \geq 0+}$ with the following
properties:
\begin{itemize}
\item $B_{0}=0$ 
\item The function $t \rightarrow B_{t}$ is almost surely continuous in $t$ 
\item The process $\left\{B_{t}\right\}_{t \geq 0}$ has stationary, independent increments
\item The increment $B_{t+s}-B_{s}$ has the $\mathcal{N}(0, t)$ distribution
\end{itemize}

\subsection{Martingale} $\mathrm{An}\left(\mathcal{F}_{t}\right)$ -adapted, real-valued process $M$ is called a martingale (with respect
to the filtration $\left(\mathcal{F}_{t}\right)$ if
\begin{itemize}
\item $\mathrm{E}\left|M_{t}\right|<\infty$ for all $t \in T$
\item $\mathrm{E}\left(M_{t} | \mathcal{F}_{s}\right) \stackrel{\mathrm{as.}}{=} M_{s}$ for all $s \leq t$
\end{itemize}

\subsection{Girsanov}  Let $B_{t}, 0 \leq t \leq T$ be a Brownian motion on a probability space
$(\Omega, \mathcal{F}, P),$ and let $\mathcal{F}_{t}, 0 \leq t \leq T,$ be a filtration for this Brownian motion. Let $a_{t}$ be an
adapted process. Define
$$ Z_{t} =\exp \left(-\int_{0}^{t} a_{u} d B_{u}-\frac{1}{2} \int_{0}^{t} a_{u}^{2} d u\right)$$
$$\tilde{B}_{t} =B_{t}+\int_{0}^{t} a_{u} d u $$
and the probability $\tilde{P}$ equivalent to $P$ defined by
$$\tilde{P}(A)=\int_{A} Z(\omega) d P(\omega)$$
and assume that
$$E\left[\int_{0}^{t} a_{u}^{2} Z_{u}^{2} d u\right]<+\infty$$
Then under the probability $\tilde{P}$ the process $\tilde{B}$ is a Brownian motion.

\subsection{It\^{o} Process} 
A process $X_{t}$ is said to be an It\^{o} process if there exist progressively measurable processes
$\alpha_{t}$ and $\beta_{t}$ such that 
$$\int_{0}^{t}\left(\left|\alpha_{s}\right|+\beta_{s}^{2}\right) d s<\infty, \text{a.s.}$$
$$X_{t}=X_{0}+\int_{0}^{t} \alpha_{S} d s+\int_{0}^{t} \beta_{s} d B_{s}$$


\subsection{ It\^{o}'s Lemma}
Let $f(t, x)$ be a real-valued function whose second-order partial derivatives are continuous. Let $\left(X_{t}\right)_{t \geq 0}$ be an  It\^{o} process, Then
$$d f(t,X)=\frac{\partial f}{\partial t}dt+\frac{\partial f}{\partial x}dX+\frac{1}{2} \frac{\partial^{2} f}{\partial x^{2}}d\langle X \rangle_t$$

\subsection{Levy Theorem} 
Let $M_t$ be a martingale with continuous sample paths and $M_{0}=0$.  Then
$$d\langle M \rangle_t=dt \iff M ~\text{is a Brownian motion}$$

\subsection{Martingale representation Theorem} 
Let $B_{t}$ be a Brownian motion and  ${\mathcal {F}}_{t}$ the augmented filtration generated by $B_{t}$. If $X$ is an ${\mathcal {F}}_{\infty}$-measurable square integrable random variable, then there is a unique $ {\mathcal {F}}_{t}$-adapted predictable process $\phi$, such that
$$X=\mathbf{E}[X]+\int_{0}^{\infty} \phi_{s} d B_{s}$$


\subsection{Symmetric Matrices} 
Any symmetric matrix $A$ ($A=A^{T}$)
\begin{itemize}
\item  has only real eigenvalues
\item is always diagonalizable
\item has orthogonal eigenvectors
\end{itemize}

\subsection{Semidefinite Positive Matrices} 
The symmetric matrix $A$ is said positive semidefinite $(A \geq 0)$ if allits eigenvalues are non negative.

\subsection{Useful Talor Series} 

\begin{align}
\frac{1}{1-x}\quad&=\quad1+x+x^{2}+x^{3}+x^{4}+\ldots \nonumber \\
e^{x} \quad&=\quad 1+x+\frac{x^{2}}{2 !}+\frac{x^{3}}{3 !}+\frac{x^{4}}{4 !}+\ldots \nonumber \\
\cos x \quad&=\quad 1-\frac{x^{2}}{2 !}+\frac{x^{4}}{4 !}-\frac{x^{6}}{6 !}+\frac{x^{8}}{8 !}-\ldots \nonumber \\
\sin x \quad&=\quad x-\frac{x^{3}}{3 !}+\frac{x^{5}}{5 !}-\frac{x^{7}}{7 !}+\frac{x^{9}}{9 !}-\cdots \nonumber
\end{align}

#########################################################################

We use the notation [h,h,h,t] for the current coins position, where h stands for heads and t for tails. We group the coins positions in classes which are stable by cyclical permutation. That means for example that [t,h,h,h], [h,t,h,h], [h,h,t,h] are grouped in the same class. Each time the player asks the game master if the current position is a winning position he can also flip all the coins and test the complementary position too. Therefore we can include the complementaries in the classes, which means that [t,h,h,h], [h,t,t,t], [h,t,h,h], [t,h,t,t] etc... are in a same class.

We use the notation [f,o,o,o] to indicate which coins are flipped by the player, f stands for flipped and o indicates that the coins are not flipped. Similarly we group the player moves in classes which are stable by cyclical permutation. 

$$\text{Position Classes}\begin{cases}
  p_1 : \text{[h,h,h,h]}\\    
  p_2 : \text{[t,h,h,h]}\\    
p_3 : \text{[t,t,h,h]}\\    
p_4 : \text{[t,h,t,h]}  
\end{cases}
\text{Transition Classes}\begin{cases}
  t_1 : \text{[f,f,f,f]}\\    
  t_2 : \text{[f,o,o,o]}\\    
t_3 : \text{[f,f,o,o]}\\    
t_4 : \text{[f,o,f,o]}  
\end{cases}$$

The transition $t_1$ is used at every step to check the complementary position. The position class $p_1$ is a winning position. We draw the following transition diagram


\usetikzlibrary{positioning,automata,arrows}
\begin{tikzpicture}[node distance=2cm]
\node[state] (1) {$p_1$};
\node[state,right of=1] (2) {$p_2$};
\node[state, above of=1] (4) {$p_4$};
\node[state, above of=2] (3) {$p_3$};
\path[->] (2) edge[loop right] node{$t_3$} (2)
(3) edge[loop right] node{$t_4$} (3)
(2) edge[above,pos=0.05] node{$t_2$} (4)
(2) edge[below] node{$t_2$} (1)
(2) edge[right] node{$t_2$} (3)
(3) edge[above] node{$t_3$} (4)
(4) edge[left] node{$t_4$} (1)
(3) edge[left,pos=0.05] node{$t_3$} (1)
(2) edge[loop below] node{$t_4$} (2);
\end{tikzpicture}


We notice that the transition $t_4$ applied on $p_4$ always leads to $p_1$. We can also see that $p_2$ and $p_3$ are stable by $t_4$. Note that the diagram does not include some adverse transitions, for example $t_2$ applied to $p_4$ sends back to $p_2$. But we can find a winning strategy with the information available in the diagram
\begin{itemize}
\item We ask if the starting position is a winning one. If not we are not in $p_1$
\item We start by applying $t_4$. If we land in a winning position then we were in $p_4$. If not, we are either in $p_2$ or $p_3$.
\item We apply now $t_3$ and then $t_4$. If we land in a winning position (after the first move or after the second move, remember we always) we can confirm we were in $p_3$ otherwise we were in $p_2$
\item We know now that we are in $p_2$. We apply $t_2$, $t_3$ and $t_4$ to win.
\end{itemize}

The winning algorithm including the complementary check is therefore

$$t_4, t_1,t_3,t_1,t_4,t_1,t_2,t_1,t_3,t_1,t_4,t_1$$



\subsection{baguettes uniform}
$$I=\displaystyle\int_{x=0}^{x=1}\int_{y=x}^{y=1}\int_{z=y}^{1\wedge(x+y)}dxdydz$$

$$I=\displaystyle\int_{x=0}^{x=1}\int_{y=x}^{y=1}\Big[x \wedge (1-y) \Big]dxdy$$

$$Y=(1-y)$$
$$I=\displaystyle\int_{x=0}^{x=1}\int_{Y=0}^{Y=1-x}\Big[x \wedge Y \Big]dxdY$$

$$I=\displaystyle\int_{x=0}^{x=\frac{1}{2}}\int_{Y=0}^{Y=x}YdxdY+\int_{x=0}^{x=\frac{1}{2}}\int_{Y=x}^{Y=1-x}xdxdY+\int_{x=\frac{1}{2}}^{x=1}\int_{Y=0}^{Y=1-x}YdxdY$$

$$I_1=\displaystyle\int_{x=0}^{x=\frac{1}{2}}\int_{Y=0}^{Y=x}YdxdY=\int_{x=0}^{x=\frac{1}{2}}\frac{x^2}{2}dx$$

$$I_2=\displaystyle\int_{x=0}^{x=\frac{1}{2}}\int_{Y=x}^{Y=1-x}xdxdY=\int_{x=0}^{x=\frac{1}{2}}x(1-2x)dx$$

$$I_3=\displaystyle\int_{x=\frac{1}{2}}^{x=1}\int_{Y=0}^{Y=1-x}YdxdY=\int_{x=\frac{1}{2}}^{x=1}\frac{(1-x)^2}{2}dx=\int_{s=\frac{1}{2}}^{s=0}-\frac{s^2}{2}ds=\int_{x=0}^{x=\frac{1}{2}}\frac{s^2}{2}dx$$

$$I=\int_{x=0}^{x=\frac{1}{2}}\frac{x^2}{2}+\frac{x^2}{2}+x(1-2x)dx=\int_{x=0}^{x=\frac{1}{2}}x(1-x)dx=\left[\frac{x^2}{2}-\frac{x^3}{3}\right]_0^{\frac{1}{2}}=\frac{1}{12}$$
$$P=6I=\frac{1}{2}$$




